#region import and initialization
import credentials
import plot_library
from pymongo import MongoClient
from bson import ObjectId
from connectionDB import getDb
from ast import literal_eval
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from keras.backend import clear_session
from keras.models import load_model
from keras.callbacks import ModelCheckpoint
from collections import Counter
from sklearn.metrics import confusion_matrix

no_key_pressed_symbol = 0 # by what symbol should "no key pressed" be represented
plot_data = True # should we plot the data
plot_history_training = True # should we plot the training history
client = MongoClient()
client = MongoClient('mongodb://%s:%s@54.152.156.242:27017' % (credentials._username, credentials._password))
db_name = 'firstdb'
db = client[db_name]
save_data_to_csv = False # saves data to a local csv
save_model_to_h5 = False
window_samples = 6
verbosity=1
dBFilter = {"user_name":"xperia", "comment":"200 hits"}
firstsTimestamps = np.loadtxt("data/firstsTimestamps.csv", delimiter = ",")
# Neural network hyperpara
nb_epochs = 40
#endregion


def formatData(window_samples, dBFilter, verbosity = False):
    accelerometer = []
    comments = []
    id = []
    print("Getting data with the following filter: ", dBFilter)
    dBResults = getDb(dBFilter, verbosity)

    for dBResult in dBResults.find(dBFilter):
        accelerometerRecord = [[], [], [], []]
        buttonRecord = [[], []]
        accelerometerRecords = literal_eval(dBResult["accelerometerRecords"])
        buttonRecords = literal_eval(dBResult["buttonRecords"])
        id.append(dBResult["id"])
        comments.append(dBResult["comment"])
        for x in range(int(len(buttonRecords) / 2)):
            buttonRecord[0].append(buttonRecords[2*x])
            buttonRecord[1].append(buttonRecords[2 * x + 1])
        # Partition timestamp, x, y and z axis
        for x in range(int(len(accelerometerRecords)/4)):
            accelerometerRecord[0].append(accelerometerRecords[4*x])
            accelerometerRecord[1].append(accelerometerRecords[4*x + 1])
            accelerometerRecord[2].append(accelerometerRecords[4*x + 2])
            accelerometerRecord[3].append(accelerometerRecords[4*x + 3])
        accelerometer.append(accelerometerRecord)
        # z is the vertical axis. We remove the gravity constant
        z_mean = np.mean(accelerometerRecord[3])
        accelerometerRecord[3] = [a - z_mean for a in accelerometerRecord[3]]
        # generate buttons column
        being_pressed = False
        cursor = 0
        current_key = no_key_pressed_symbol
        button_pressed = []
        button_1_0 = []
        print("Formatting the button data")
        for k in range(len(accelerometer[0][0])):
            if being_pressed:
                if buttonRecord[0][cursor]<accelerometer[0][0][k] and cursor < len(buttonRecord[0])-1:
                    cursor +=1
                    being_pressed = False
                    current_key = buttonRecord[1][cursor]
            else:
                if buttonRecord[0][cursor]<accelerometer[0][0][k] and cursor < len(buttonRecord[0]):
                    cursor +=1
                    being_pressed = True
                    current_key = no_key_pressed_symbol
            button_pressed.append(current_key)
            button_1_0.append(1 if current_key !=no_key_pressed_symbol else 0) 
        
        print("Formatting time data")
        timestart = min(accelerometer[0][0][0], buttonRecord[0][0]) # accelerometer records and button pressed are asynchronous, so we take the minimum of the two
        buttonRecord[0] = [b - timestart for b in buttonRecord[0]] 
        time = [t - timestart for t in accelerometer[0][0]]
        print("Interpolating accelerometer data")
        interpolated = [[accelerometer[0][1][k+row] for k in range(6)] + 
                [accelerometer[0][2][k+row] for k in range(6)] + 
                [accelerometer[0][3][k+row] for k in range(6)] for row in range(0,len(accelerometer[0][1])-window_samples+1)]
        print("Interpolating binary button data")
        button_summed_on_window = np.convolve(button_1_0, np.ones(window_samples,dtype=int),'valid')
        interpolated_button = [1 if button_summed_on_window[k]>3 else 0 for k in range(len(button_summed_on_window)) ]
        print("Interpolating category button data")
        button_category = [Counter([button_pressed[k+row] for k in range(window_samples)]).most_common(1)[0][0] 
                          for row in range(0,len(button_pressed)-window_samples+1)]
        button_category_list = [[0 for i in range(10)] for k in range(len(button_category))]
        for k in range(len(button_category)):
            button_category_list[k][button_category[k]] = 1
        
        
    return np.array(interpolated), np.array(interpolated_button), time, np.array(button_category_list), buttonRecord, accelerometerRecord


X, Y_binary, time, Y_category, buttonRecord, accelerometerRecord = formatData(window_samples, dBFilter)
Y = Y_binary
# fix seed for reproducibility
seed = 12
np.random.seed(seed)
clear_session()

print("Splitting training data")
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)

# create binary model
binary_model = Sequential()
# binary_model.add(Dense(window_samples * 4, input_dim= window_samples * 3, activation='relu'))
binary_model.add(Dense(window_samples * 4, input_dim= window_samples * 3, activation='relu',kernel_initializer='random_normal'))
binary_model.add(Dense(window_samples * 2, activation='relu',kernel_initializer='random_normal'))
binary_model.add(Dense(window_samples, activation='relu',kernel_initializer='random_normal'))
binary_model.add(Dense(1, activation='sigmoid',kernel_initializer='random_normal'
)) # sigmoid for binary classification

checkpoint = ModelCheckpoint('data/binary_model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  

binary_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history_binary_model = binary_model.fit(X_train, Y_train,
    validation_data=(X_test, Y_test),
    nb_epoch=nb_epochs,
    batch_size=20,  
    verbose=verbosity,
    callbacks = [checkpoint])

binary_model.summary()
#binary_model.save('data/binary_model.h5')  # creates a HDF5 file 'my_model.h5'
    
Y = Y_category
print("Splitting training data")
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)

# create category model
category_model = Sequential()
# category_model.add(Dense(window_samples * 4, input_dim= window_samples * 3, activation='relu'))
category_model.add(Dense(window_samples * 4, input_dim= window_samples * 3, activation='relu',kernel_initializer='random_normal'))
category_model.add(Dense(window_samples * 2, activation='relu',kernel_initializer='random_normal'))
category_model.add(Dense(window_samples, activation='relu',kernel_initializer='random_normal'))
category_model.add(Dense(10, activation='softmax',kernel_initializer='random_normal')) # softmax for category classification when you only want ONE label

checkpoint = ModelCheckpoint('data/category_model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  

category_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history_category_model = category_model.fit(X_train, Y_train,
    validation_data=(X_test, Y_test),
    nb_epoch=nb_epochs,
    batch_size=20,  
    verbose=verbosity,
    callbacks = [checkpoint])

category_model.summary()
if plot_history_training:
    plot_library.plot_history_accuracy_loss(history_binary_model,1)
    plot_library.plot_history_accuracy_loss(history_category_model,2)
    plt.show()
#binary_model.save('data/category_model.h5')  # creates a HDF5 file 'my_model.h5'

# Evaluate the model on the test data using `evaluate`
print('\n# Evaluate on test data')
results = category_model.evaluate(X_test, Y_test, batch_size=128)
print('test loss, test acc:', results)

# Generate predictions (probabilities -- the output of the last layer)
# on new data using `predict`

print('\n# Generate predictions for binary model')
predictions = binary_model.predict(X)
binary_predictions = [1 if (b[0] > 0.5) else 0 for b in predictions]
print(confusion_matrix(Y_binary, binary_predictions))

print('\n# Generate predictions for categorical model')
predictions = category_model.predict(X)
predicted_category = np.argmax(predictions, axis=1)
predicted_category_counter = Counter(predicted_category)
real_category = np.argmax(Y_category, axis=1)
real_category_counter = Counter(real_category)
#print('predictions :', predicted_category_counter)
#print("real : ", real_category_counter)
print(confusion_matrix(real_category, predicted_category))
# if you want to plot:
# to plot data, we show 3 figures (one for each axis) with the accelerometer values?=. Note that we don't plt.show() right now
if plot_data:
    filename = "accelerometer"
    plot_library.plot_values_and_real_and_predicted_buttons(list(predicted_category),
        buttonRecord[0], buttonRecord[1],time, accelerometerRecord[1], 1,filename+' X', window_samples)
    plot_library.plot_values_and_real_and_predicted_buttons(list(predicted_category),
        buttonRecord[0], buttonRecord[1],time, accelerometerRecord[2], 2,filename+' Y', window_samples)
    plot_library.plot_values_and_real_and_predicted_buttons(list(predicted_category),
        buttonRecord[0], buttonRecord[1],time, [a - np.mean(accelerometerRecord[3]) for a in accelerometerRecord[3]], 3,filename+' Z', window_samples) # remove gravity
    

if save_data_to_csv: 
    print("Saving data to csv")
    np.savetxt("data/X_train.csv", X_train, delimiter = ",")
    np.savetxt("data/X_test.csv", X_test, delimiter = ",")
    np.savetxt("data/Y_train_int.csv", Y_train, delimiter = ",")
    np.savetxt("data/Y_test_int.csv", Y_test, delimiter = ",")
    # X_train = np.loadtxt("X_train.csv", delimiter = ",")
 
# if you want to save your model
if save_model_to_h5:
    model.save('data/my_model.h5')  # creates a HDF5 file 'my_model.h5'
    # returns a compiled model
    # identical to the previous one
    model = load_model('data/my_model.h5')

# if needed, to have more button pressed than no button pressed
import random
for k in range(len(Y_train)):
    print(k)
    if Y_train[k]==False:
        print(k)
        if random.random()>0.5:
            print(" DELETE ")
            X_train = np.delete(X_train, k,0)
            Y_train = np.delete(Y_train, k,0)
